{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95149752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declaring the imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../data/Training.csv\"\n",
    "TEST_PATH = \"../data/Testing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ba9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd540a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the target column\n",
    "def detect_target_column(df):\n",
    "    candidates = ['Disease', 'Prognosis', 'prognosis', 'disease']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(f\"Could not find target column among { candidates }. Found: { list(df.columns) }\")\n",
    "\n",
    "# Detect the symptom columns\n",
    "def detect_symptom_columns(df):\n",
    "    target_column = detect_target_column(df)\n",
    "    cols = [c for c in df.columns if c != target_column]\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Symptom labels\n",
    "def encode_labels(raw_values):\n",
    "    classes = list(dict.fromkeys(pd.Series(raw_values).astype(str)))\n",
    "    cls_to_int = { c: i for i, c in enumerate(classes) }\n",
    "    int_values = np.array([cls_to_int[str(v)] for v in raw_values], dtype = np.int64)\n",
    "    return int_values, classes, cls_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the User given text input to create the input vector for the model\n",
    "def clean_symptom_text(user_input):\n",
    "    user_input = user_input.lower()\n",
    "    user_input = re.sub(r'[^a-z\\s]', '', user_input)\n",
    "    words = user_input.split()\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20640d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the one-hot encoding function\n",
    "def one_hot(y_int, n_classes):\n",
    "    y = np.zeros((y_int.shape[0], n_classes), dtype = np.float32)\n",
    "    y[np.arange(y_int.shape[0]), y_int] = 1.0\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the User Vector build method\n",
    "def build_user_vector(user_input_text, symptom_index):\n",
    "    vector = np.zeros((1, len(symptom_index)), dtype = np.float32)\n",
    "    if user_input_text:\n",
    "        user_symptoms = [s.strip().lower() for s in user_input_text.split(\",\")]\n",
    "        for s in user_symptoms:\n",
    "            if s in symptom_index:\n",
    "                vector[0, symptom_index[s]] = 1.0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Dense Neural Network Layer class\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_outputs, w_init):\n",
    "        if w_init == \"he\":\n",
    "            self.w = np.random.randn(n_inputs, n_outputs) * np.sqrt(2.0 / n_inputs)\n",
    "        elif w_init == \"xavier\":\n",
    "            self.w = np.random.randn(n_inputs, n_outputs) * np.sqrt(1.0 / n_inputs)\n",
    "        self.b = np.zeros((1, n_outputs))\n",
    "        self.dw = np.zeros_like(self.w)\n",
    "        self.db = np.zeros_like(self.b)\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.w) + self.b\n",
    "    \n",
    "    def backward_pass(self, dz):\n",
    "        self.dw = np.dot(self.x.T, dz)\n",
    "        self.db = np.sum(dz, axis = 0, keepdims = True)\n",
    "        dx = np.dot(dz, self.w.T)\n",
    "        return dx\n",
    "    \n",
    "    def step(self, lr):\n",
    "        self.w -= lr * self.dw\n",
    "        self.b -= lr * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the ReLU activation function class\n",
    "class ReLU_Activation:\n",
    "    def forward_pass(self, z):\n",
    "        self.z = z\n",
    "        return np.maximum(0.0, z)\n",
    "    def backward_pass(self, dvalues_a):\n",
    "        dz = dvalues_a.copy()\n",
    "        dz[self.z <= 0.0] = 0\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fddc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Softmax activation function class\n",
    "class Softmax_Activation:\n",
    "    def forward_pass(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis = 1, keepdims = True))\n",
    "        self.probabilities = exp_values / np.sum(exp_values, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66812ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of common Loss class\n",
    "class Loss:\n",
    "    def calculate_loss(self, outputs, t_values):\n",
    "        sample_losses = self.forward_pass(outputs, t_values)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb566bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemention Categorical Cross-entropy Loss class\n",
    "class CategoricalCrossEntropy_Loss:\n",
    "    def calculate_loss(self, p_values, t_values):\n",
    "        samples = len(p_values)\n",
    "        p_values_clipped = np.clip(p_values, 1e-7, 1 - 1e-7)\n",
    "        if len(t_values.shape) == 1:\n",
    "            correct_confidences = p_values_clipped[range(samples), t_values]\n",
    "        elif len(t_values.shape) == 2:\n",
    "            correct_confidences = np.sum(p_values_clipped * t_values, axis = 1)\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return np.mean(negative_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the combined Softmax activation and Cross-entropy loss class\n",
    "class Softmax_Activation_CategoricalCrossEntropy_Loss:\n",
    "    def __init__(self):\n",
    "        self.activation = Softmax_Activation()\n",
    "        self.loss = CategoricalCrossEntropy_Loss()\n",
    "    \n",
    "    def forward_pass(self, inputs, t_values):\n",
    "        self.activation.forward_pass(inputs)\n",
    "        self.output = self.activation.probabilities\n",
    "        return self.loss.calculate_loss(self.output, t_values)\n",
    "    \n",
    "    def backward_pass(self, d_values, t_values):\n",
    "        samples = len(d_values)\n",
    "        if len(t_values.shape) == 2:\n",
    "            t_values = np.argmax(t_values, axis = 1)\n",
    "        self.d_inputs = d_values.copy()\n",
    "        self.d_inputs[range(samples), t_values] -= 1\n",
    "        self.d_inputs = self.d_inputs / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the core MLP class\n",
    "class MLP:\n",
    "    def __init__(self, input_dim, hidden1 = 64, hidden2 = 32, n_classes = 10, learning_rate = 0.01):\n",
    "        self.input_layer = Layer_Dense(input_dim, hidden1, w_init = \"he\")\n",
    "        self.activation_1 = ReLU_Activation()\n",
    "        self.hidden_layer_1 = Layer_Dense(hidden1, hidden2, w_init = \"he\")\n",
    "        self.activation_2 = ReLU_Activation()\n",
    "        self.hidden_layer_2 = Layer_Dense(hidden2, n_classes, w_init = \"xavier\")\n",
    "        self.softmax_loss = Softmax_Activation_CategoricalCrossEntropy_Loss()\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def forward(self, x, y_true = None):\n",
    "        z1 = self.input_layer.forward_pass(x)\n",
    "        a1 = self.activation_1.forward_pass(z1)\n",
    "        z2 = self.hidden_layer_1.forward_pass(a1)\n",
    "        a2 = self.activation_2.forward_pass(z2)\n",
    "        z3 = self.hidden_layer_2.forward_pass(a2)\n",
    "        if y_true is not None:\n",
    "            loss = self.softmax_loss.forward_pass(z3, y_true)\n",
    "            return self.softmax_loss.output, loss\n",
    "        self.softmax_loss.activation.forward_pass(z3)\n",
    "        return self.softmax_loss.activation.probabilities\n",
    "    \n",
    "    def backward(self, y_true):\n",
    "        self.softmax_loss.backward_pass(self.softmax_loss.output, y_true)\n",
    "        da2 = self.hidden_layer_2.backward_pass(self.softmax_loss.d_inputs)\n",
    "        dz2 = self.activation_2.backward_pass(da2)\n",
    "        da1 = self.hidden_layer_1.backward_pass(dz2)\n",
    "        dz1 = self.activation_1.backward_pass(da1)\n",
    "        _ = self.input_layer.backward_pass(dz1)\n",
    "    \n",
    "    def w_step(self):\n",
    "        for layer in [self.input_layer, self.hidden_layer_1, self.hidden_layer_2]:\n",
    "            layer.step(self.learning_rate)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        probs = self.forward(x)\n",
    "        return np.argmax(probs, axis = 1), probs\n",
    "    \n",
    "    def fit(self, x, y_one_hot, epochs = 50, batch_size = 64, x_val = None, y_val = None):\n",
    "        n = x.shape[0]\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            idx = np.random.permutation(n)\n",
    "            x, y_one_hot = x[idx], y_one_hot[idx]\n",
    "            epoch_loss = 0.0\n",
    "            seen = 0\n",
    "            for start in range(0, n, batch_size):\n",
    "                end = min(start + batch_size, n)\n",
    "                xb, yb = x[start : end], y_one_hot[start : end]\n",
    "                probs, loss = self.forward(xb, yb)\n",
    "                self.backward(yb)\n",
    "                self.w_step()\n",
    "                epoch_loss += loss * (end - start)\n",
    "                seen += (end - start)\n",
    "            epoch_loss /= loss\n",
    "            if epoch == 1 or epoch % 5 == 0:\n",
    "                if x_val is not None and y_val is not None:\n",
    "                    y_pred, _ = self.predict(x_val)\n",
    "                    val_acc = (y_pred == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Main method\n",
    "def main():\n",
    "    train_df = load_data(TRAIN_PATH)\n",
    "    test_df = load_data(TEST_PATH)\n",
    "\n",
    "    if \"Unnamed: 133\" in train_df.columns:\n",
    "        train_df.drop('Unnamed: 133', axis=1, inplace=True)\n",
    "    if \"Unnamed: 133\" in test_df.columns:\n",
    "        test_df.drop('Unnamed: 133', axis=1, inplace=True)\n",
    "\n",
    "    target_column = detect_target_column(train_df)\n",
    "    symptom_columns = detect_symptom_columns(train_df)\n",
    "    \n",
    "    x_train = train_df[symptom_columns].values.astype(np.float32)\n",
    "    y_train_int, classes, cls_to_int = encode_labels(train_df[target_column].astype(str).values)\n",
    "    y_train_one_hot = one_hot(y_train_int, len(classes))\n",
    "\n",
    "    x_test = test_df[symptom_columns].values.astype(np.float32)\n",
    "    y_test_int = np.array([cls_to_int[str(v)] for v in test_df[target_column].astype(str).values], dtype = np.int64)\n",
    "    y_test_one_hot = one_hot(y_test_int, len(classes))\n",
    "\n",
    "    # print(f\"Shape of x_test before fit: {x_test.shape}\")\n",
    "    # print(f\"Shape of y_test_int before fit: {y_test_int.shape}\")\n",
    "\n",
    "    model = MLP(x_train.shape[1], 64, 32, len(classes), 0.01)\n",
    "    model.fit(x_train, y_train_one_hot, 50, 64, x_test, y_test_int)\n",
    "\n",
    "    y_pred, _ = model.predict(x_test)\n",
    "    print(f\"\\nTest accuracy: {(y_pred == y_test_int).mean():.4f}\")\n",
    "\n",
    "    symptom_index = {s.lower(): i for i, s in enumerate(symptom_columns)}\n",
    "    print(\"\\nEnter symptoms separated by commas (empty line to exit):\")\n",
    "    while True:\n",
    "        user_text = input(\"\\nYour symptoms: \").strip()\n",
    "        if not user_text:\n",
    "            break\n",
    "        x_vec = build_user_vector(user_text, symptom_index)\n",
    "        pred_idx, probs = model.predict(x_vec)\n",
    "        print(f\"=> Predicted disease: {classes[pred_idx[0]]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Main method\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
