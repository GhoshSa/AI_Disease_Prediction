{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95149752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declaring the imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbcbf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the CSV files\n",
    "TRAIN_PATH = \"../data/Training.csv\"\n",
    "TEST_PATH = \"../data/Testing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "974ba9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading the CSV files\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd540a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the target column\n",
    "def detect_target_column(df):\n",
    "    candidates = ['Disease', 'Prognosis', 'prognosis', 'disease']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(f\"Could not find target column among { candidates }. Found: { list(df.columns) }\")\n",
    "\n",
    "# Detect the symptom columns\n",
    "def detect_symptom_columns(df):\n",
    "    target_column = detect_target_column(df)\n",
    "    cols = [c for c in df.columns if c != target_column]\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2eda2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Symptom labels\n",
    "def encode_labels(raw_values):\n",
    "    classes = list(dict.fromkeys(pd.Series(raw_values).astype(str)))\n",
    "    cls_to_int = { c: i for i, c in enumerate(classes) }\n",
    "    int_values = np.array([cls_to_int[str(v)] for v in raw_values], dtype = np.int64)\n",
    "    return int_values, classes, cls_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df53b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the User given text input to create the input vector for the model\n",
    "def clean_symptom_text(user_input):\n",
    "    user_input = user_input.lower()\n",
    "    user_input = re.sub(r'[^a-z\\s]', '', user_input)\n",
    "    words = user_input.split()\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20640d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the one-hot encoding function\n",
    "def one_hot(y_int, n_classes):\n",
    "    y = np.zeros((y_int.shape[0], n_classes), dtype = np.float32)\n",
    "    y[np.arange(y_int.shape[0]), y_int] = 1.0\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32fe8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the User Vector build method\n",
    "def build_user_vector(user_input_text, symptom_index):\n",
    "    vector = np.zeros((1, len(symptom_index)), dtype = np.float32)\n",
    "    if user_input_text:\n",
    "        user_symptoms = [s.strip().lower() for s in user_input_text.split(\",\")]\n",
    "        for s in user_symptoms:\n",
    "            if s in symptom_index:\n",
    "                vector[0, symptom_index[s]] = 1.0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5d9921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Dense Neural Network Layer class\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_outputs, w_init):\n",
    "        if w_init == \"he\":\n",
    "            self.w = np.random.randn(n_inputs, n_outputs) * np.sqrt(2.0 / n_inputs)\n",
    "        elif w_init == \"xavier\":\n",
    "            self.w = np.random.randn(n_inputs, n_outputs) * np.sqrt(1.0 / n_inputs)\n",
    "        self.b = np.zeros((1, n_outputs))\n",
    "        self.dw = np.zeros_like(self.w)\n",
    "        self.db = np.zeros_like(self.b)\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.w) + self.b\n",
    "    \n",
    "    def backward_pass(self, dz):\n",
    "        self.dw = np.dot(self.x.T, dz)\n",
    "        self.db = np.sum(dz, axis = 0, keepdims = True)\n",
    "        dx = np.dot(dz, self.w.T)\n",
    "        return dx\n",
    "    \n",
    "    def step(self, lr):\n",
    "        self.w -= lr * self.dw\n",
    "        self.b -= lr * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0707583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the ReLU activation function class\n",
    "class ReLU_Activation:\n",
    "    def forward_pass(self, z):\n",
    "        self.z = z\n",
    "        return np.maximum(0.0, z)\n",
    "    def backward_pass(self, dvalues_a):\n",
    "        dz = dvalues_a.copy()\n",
    "        dz[self.z <= 0.0] = 0\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7fddc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Softmax activation function class\n",
    "class Softmax_Activation:\n",
    "    def forward_pass(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis = 1, keepdims = True))\n",
    "        self.probabilities = exp_values / np.sum(exp_values, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66812ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of common Loss class\n",
    "class Loss:\n",
    "    def calculate_loss(self, outputs, t_values):\n",
    "        sample_losses = self.forward_pass(outputs, t_values)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6fb566bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemention Categorical Cross-entropy Loss class\n",
    "class CategoricalCrossEntropy_Loss:\n",
    "    def calculate_loss(self, p_values, t_values):\n",
    "        samples = len(p_values)\n",
    "        p_values_clipped = np.clip(p_values, 1e-7, 1 - 1e-7)\n",
    "        if len(t_values.shape) == 1:\n",
    "            correct_confidences = p_values_clipped[range(samples), t_values]\n",
    "        elif len(t_values.shape) == 2:\n",
    "            correct_confidences = np.sum(p_values_clipped * t_values, axis = 1)\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return np.mean(negative_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a79eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the combined Softmax activation and Cross-entropy loss class\n",
    "class Softmax_Activation_CategoricalCrossEntropy_Loss:\n",
    "    def __init__(self):\n",
    "        self.activation = Softmax_Activation()\n",
    "        self.loss = CategoricalCrossEntropy_Loss()\n",
    "    \n",
    "    def forward_pass(self, inputs, t_values):\n",
    "        self.activation.forward_pass(inputs)\n",
    "        self.output = self.activation.probabilities\n",
    "        return self.loss.calculate_loss(self.output, t_values)\n",
    "    \n",
    "    def backward_pass(self, d_values, t_values):\n",
    "        samples = len(d_values)\n",
    "        if len(t_values.shape) == 2:\n",
    "            t_values = np.argmax(t_values, axis = 1)\n",
    "        self.d_inputs = d_values.copy()\n",
    "        self.d_inputs[range(samples), t_values] -= 1\n",
    "        self.d_inputs = self.d_inputs / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "606583dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Dropout class\n",
    "class Dropout:\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "\n",
    "    def forward_pass(self, x, training = True):\n",
    "        if not training:\n",
    "            return x\n",
    "        self.mask = np.random.binomial(1, 1 - self.rate, size=x.shape) / (1 - self.rate)\n",
    "        return x * self.mask\n",
    "    \n",
    "    def backward_pass(self, d_values):\n",
    "        return d_values * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11af32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the core MLP class\n",
    "class MLP:\n",
    "    def __init__(self, input_dim, hidden1 = 64, hidden2 = 32, n_classes = 10, learning_rate = 0.01, dropout_rate = 0.2):\n",
    "        self.input_layer = Layer_Dense(input_dim, hidden1, w_init = \"he\")\n",
    "        self.activation_1 = ReLU_Activation()\n",
    "        self.dropout_1 = Dropout(dropout_rate)\n",
    "        self.hidden_layer_1 = Layer_Dense(hidden1, hidden2, w_init = \"he\")\n",
    "        self.activation_2 = ReLU_Activation()\n",
    "        self.dropout_2 = Dropout(dropout_rate)\n",
    "        self.hidden_layer_2 = Layer_Dense(hidden2, n_classes, w_init = \"xavier\")\n",
    "        self.softmax_loss = Softmax_Activation_CategoricalCrossEntropy_Loss()\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def forward(self, x, y_true = None):\n",
    "        z1 = self.input_layer.forward_pass(x)\n",
    "        a1 = self.activation_1.forward_pass(z1)\n",
    "        d_a1 = self.dropout_1.forward_pass(a1, True)\n",
    "        z2 = self.hidden_layer_1.forward_pass(d_a1)\n",
    "        a2 = self.activation_2.forward_pass(z2)\n",
    "        d_a2 = self.dropout_2.forward_pass(a2, True)\n",
    "        z3 = self.hidden_layer_2.forward_pass(d_a2)\n",
    "        if y_true is not None:\n",
    "            loss = self.softmax_loss.forward_pass(z3, y_true)\n",
    "            return self.softmax_loss.output, loss\n",
    "        self.softmax_loss.activation.forward_pass(z3)\n",
    "        return self.softmax_loss.activation.probabilities\n",
    "    \n",
    "    def backward(self, y_true):\n",
    "        self.softmax_loss.backward_pass(self.softmax_loss.output, y_true)\n",
    "        da2 = self.hidden_layer_2.backward_pass(self.softmax_loss.d_inputs)\n",
    "        dz2 = self.activation_2.backward_pass(da2)\n",
    "        d_dz2 = self.dropout_2.backward_pass(dz2)\n",
    "        da1 = self.hidden_layer_1.backward_pass(d_dz2)\n",
    "        dz1 = self.activation_1.backward_pass(da1)\n",
    "        d_dz1 = self.dropout_1.backward_pass(dz1)\n",
    "        _ = self.input_layer.backward_pass(d_dz1)\n",
    "    \n",
    "    def w_step(self):\n",
    "        for layer in [self.input_layer, self.hidden_layer_1, self.hidden_layer_2]:\n",
    "            layer.step(self.learning_rate)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        probs = self.forward(x)\n",
    "        return np.argmax(probs, axis = 1), probs\n",
    "    \n",
    "    def fit(self, x, y_one_hot, epochs = 50, batch_size = 64, x_val = None, y_val = None):\n",
    "        n = x.shape[0]\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            idx = np.random.permutation(n)\n",
    "            x, y_one_hot = x[idx], y_one_hot[idx]\n",
    "            epoch_loss = 0.0\n",
    "            seen = 0\n",
    "            for start in range(0, n, batch_size):\n",
    "                end = min(start + batch_size, n)\n",
    "                xb, yb = x[start : end], y_one_hot[start : end]\n",
    "                probs, loss = self.forward(xb, yb)\n",
    "                self.backward(yb)\n",
    "                self.w_step()\n",
    "                epoch_loss += loss * (end - start)\n",
    "                seen += (end - start)\n",
    "            epoch_loss /= seen\n",
    "            if epoch == 1 or epoch % 5 == 0:\n",
    "                msg = f\"Epoch {epoch:3d} | loss {epoch_loss:.4f}\"\n",
    "                if x_val is not None and y_val is not None:\n",
    "                    y_pred, _ = self.predict(x_val)\n",
    "                    val_acc = (y_pred == y_val).mean()\n",
    "                    msg += f\" | val_acc {val_acc:.4f}\"\n",
    "                print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "073d5102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Conversation and Vector creation class\n",
    "class Conversation_and_Vector:\n",
    "    def __init__(self, model, classes, symptom_index, threshold_gap):\n",
    "        self.model = model\n",
    "        self.classes = classes\n",
    "        self.symptom_index = symptom_index\n",
    "        self.threshold_gap = threshold_gap\n",
    "        self.vector = np.zeros((1, len(symptom_index)), dtype=np.float32)\n",
    "\n",
    "    def update_vector(self, user_input):\n",
    "        tokens = [w.strip().lower() for w in re.split(r\"[,.;]\", user_input) if w.strip()]\n",
    "        for t in tokens:\n",
    "            if t in self.symptom_index:\n",
    "                self.vector[0, self.symptom_index[t]] = 1.0\n",
    "\n",
    "    def predict(self):\n",
    "        _, probs = self.model.predict(self.vector)\n",
    "        top_index_2 = np.argsort(probs[0])[-2:][::-1]\n",
    "        top_conf, second_conf = probs[0][top_index_2[0]], probs[0][top_index_2[1]]\n",
    "        top_disease, second_disease = self.classes[top_index_2[0]], self.classes[top_index_2[1]]\n",
    "        return top_disease, top_conf, second_disease, second_conf\n",
    "    \n",
    "    def conversation_loop(self):\n",
    "        while True:\n",
    "            user_input = input().strip().lower()\n",
    "            if not user_input:\n",
    "                break\n",
    "            self.update_vector(user_input)\n",
    "            top_disease, top_conf, second_disease, second_conf = self.predict()\n",
    "            # gap = top_conf - second_conf\n",
    "            # if gap >= self.threshold_gap:\n",
    "            if top_conf >= 0.9:\n",
    "                print(f\"Final prediction: { top_disease } with confidence: { top_conf }\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"It could be { top_disease } confidence: { top_conf } or { second_disease } confidence: { second_conf }. Could you share more symptoms...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c171fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Main method\n",
    "def main():\n",
    "    train_df = load_data(TRAIN_PATH)\n",
    "    test_df = load_data(TEST_PATH)\n",
    "\n",
    "    if \"Unnamed: 133\" in train_df.columns:\n",
    "        train_df.drop('Unnamed: 133', axis=1, inplace=True)\n",
    "    if \"Unnamed: 133\" in test_df.columns:\n",
    "        test_df.drop('Unnamed: 133', axis=1, inplace=True)\n",
    "\n",
    "    target_column = detect_target_column(train_df)\n",
    "    symptom_columns = detect_symptom_columns(train_df)\n",
    "    \n",
    "    x_train = train_df[symptom_columns].values.astype(np.float32)\n",
    "    y_train_int, classes, cls_to_int = encode_labels(train_df[target_column].astype(str).values)\n",
    "    y_train_one_hot = one_hot(y_train_int, len(classes))\n",
    "\n",
    "    x_test = test_df[symptom_columns].values.astype(np.float32)\n",
    "    y_test_int = np.array([cls_to_int[str(v)] for v in test_df[target_column].astype(str).values], dtype = np.int64)\n",
    "    y_test_one_hot = one_hot(y_test_int, len(classes))\n",
    "\n",
    "    # print(f\"Shape of x_test before fit: {x_test.shape}\")\n",
    "    # print(f\"Shape of y_test_int before fit: {y_test_int.shape}\")\n",
    "\n",
    "    model = MLP(x_train.shape[1], 64, 32, len(classes), 0.01)\n",
    "    model.fit(x_train, y_train_one_hot, 100, 64, x_test, y_test_int)\n",
    "\n",
    "    y_pred, _ = model.predict(x_test)\n",
    "    print(f\"\\nTest accuracy: {(y_pred == y_test_int).mean():.4f}\")\n",
    "\n",
    "    symptom_index = {s.lower(): i for i, s in enumerate(symptom_columns)}\n",
    "    print(\"\\nEnter symptoms separated by commas (empty line to exit):\")\n",
    "    # while True:\n",
    "    #     user_text = input(\"\\nYour symptoms: \").strip()\n",
    "    #     if not user_text:\n",
    "    #         break\n",
    "    #     x_vec = build_user_vector(user_text, symptom_index)\n",
    "    #     pred_idx, probs = model.predict(x_vec)\n",
    "        # print(f\"=> Predicted disease: {classes[pred_idx[0]]}\")\n",
    "    conversation_and_vector = Conversation_and_Vector(model, classes, symptom_index, 0.1)\n",
    "    conversation_and_vector.conversation_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e9a977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | loss 3.7469 | val_acc 0.0238\n",
      "Epoch   5 | loss 3.4834 | val_acc 0.0952\n",
      "Epoch  10 | loss 3.0750 | val_acc 0.2619\n",
      "Epoch  15 | loss 2.5171 | val_acc 0.4524\n",
      "Epoch  20 | loss 1.9261 | val_acc 0.6667\n",
      "Epoch  25 | loss 1.4164 | val_acc 0.7143\n",
      "Epoch  30 | loss 1.0700 | val_acc 0.8810\n",
      "Epoch  35 | loss 0.7903 | val_acc 0.8810\n",
      "Epoch  40 | loss 0.6377 | val_acc 0.8333\n",
      "Epoch  45 | loss 0.5018 | val_acc 0.8571\n",
      "Epoch  50 | loss 0.4197 | val_acc 0.9048\n",
      "Epoch  55 | loss 0.3600 | val_acc 0.9762\n",
      "Epoch  60 | loss 0.3086 | val_acc 0.9524\n",
      "Epoch  65 | loss 0.2870 | val_acc 0.9524\n",
      "Epoch  70 | loss 0.2455 | val_acc 0.9524\n",
      "Epoch  75 | loss 0.2203 | val_acc 0.9524\n",
      "Epoch  80 | loss 0.2083 | val_acc 0.9524\n",
      "Epoch  85 | loss 0.1936 | val_acc 0.9524\n",
      "Epoch  90 | loss 0.1767 | val_acc 0.9048\n",
      "Epoch  95 | loss 0.1707 | val_acc 0.9524\n",
      "Epoch 100 | loss 0.1601 | val_acc 0.9286\n",
      "\n",
      "Test accuracy: 0.9762\n",
      "\n",
      "Enter symptoms separated by commas (empty line to exit):\n",
      "It could be Drug Reaction confidence: 0.7226851069891418 or Allergy confidence: 0.14698512704241953. Could you share more symptoms...\n",
      "It could be Bronchial Asthma confidence: 0.31937131948217823 or Acne confidence: 0.29362609296159753. Could you share more symptoms...\n",
      "It could be Fungal infection confidence: 0.8959669422322026 or Drug Reaction confidence: 0.05380472500757349. Could you share more symptoms...\n",
      "Final prediction: Fungal infection with confidence: 0.9922033037997423\n"
     ]
    }
   ],
   "source": [
    "# Calling the Main method\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
